{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1acb638-96fc-4849-baf7-333688a93a9d",
   "metadata": {},
   "source": [
    "### This is a sample code running on a sample AccountOID to get the forecasted water consumption for 30 days.\n",
    "\n",
    "#### Note: Provided a sample database that contains the following attributes: AccountOID: Account ID, ConsumptionDate: Consumption Date, Consumption: Water daily Consumption (m^3)\n",
    "#### Note: The following requirements were used pandas==1.4.3, pmdarima==2.0.1, statsmodels==0.13.2, pyodbc==4.0.34\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8198a-e4c8-4587-b754-90d40ab6e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "import pyodbc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79448bc-6fb7-4674-b661-32d9f39458d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pyodbc connection \n",
    "try:\n",
    "    cnxn = pyodbc.connect(driver='{ODBC Driver 17 for SQL Server}',\n",
    "                        server='******',\n",
    "                        database='******',\n",
    "                        uid='******',\n",
    "                        pwd='******')\n",
    "    cursor = cnxn.cursor()\n",
    "    \n",
    "except pyodbc.Error as ex:\n",
    "    sqlstate = ex.args[1]\n",
    "    sqlstate = sqlstate.split(\".\")\n",
    "    print(sqlstate)\n",
    "        \n",
    "sqlfilter = \"\"\"\n",
    "             SELECT\n",
    "             [ConsumptionDaily].[ConsumptionDate],\n",
    "             [ConsumptionDaily].[Consumption]\n",
    "            FROM\n",
    "             [PORTAL].[ConsumptionDaily]\n",
    "            WHERE [ConsumptionDaily].[AccountOID] = {var1}\n",
    "            ORDER BY\n",
    "             [ConsumptionDaily].[ConsumptionDate]\n",
    "             ;\n",
    "            \"\"\".format(var1=3225298)  #sample \n",
    "df_main = pd.read_sql_query(sqlfilter, cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a366d1-2ebb-451c-9247-b06a426f7f12",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b43667-4f36-4386-8e24-89032fa1c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \n",
    "    df = df.drop('AccountOID', axis=1)\n",
    "    dates = df['ConsumptionDate'].to_list()\n",
    "    all_dates = pd.date_range(dates[0], dates[-1])\n",
    "    all_dates_df = pd.DataFrame(pd.date_range(dates[0], dates[-1]), columns=['ConsumptionDate'])\n",
    "    df['ConsumptionDate'] = pd.to_datetime(df['ConsumptionDate'])\n",
    "    df = pd.merge(all_dates_df, df, on='ConsumptionDate', how='left')\n",
    "    df['Consumption'] = df['Consumption'].fillna(0)\n",
    "    df[\"ConsumptionDate\"] = pd.to_datetime(df[\"ConsumptionDate\"])\n",
    "    df.loc[df['Consumption'] > 800, 'Consumption'] = df['Consumption'].median()\n",
    "    df = df.set_index('ConsumptionDate')\n",
    "    \n",
    "    return df\n",
    "\n",
    "data_processed = process(df_main.copy())\n",
    "data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0a16a-2e4e-48e3-9d44-b5215da08bba",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd867145-4320-4145-989a-ffbe65a8174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(dataset):\n",
    "\n",
    "    data_size = dataset.shape[0]\n",
    "    test_size = 30\n",
    "    train_X, train_y = dataset[:data_size - test_size], dataset[:data_size - test_size]\n",
    "    test_X, test_y = dataset[data_size - test_size:], dataset[data_size - test_size:]\n",
    "\n",
    "    #Automating ARIMA to choose best parameters    \n",
    "    step_wise = auto_arima(train_y,exogenous= train_X, seasonal=True,start_p=1, start_q=1, max_p=7, max_q=7,\n",
    "    error_action = 'ignore', suppress_warnings = True, stepwise=True, parallel = True, verbose=False)\n",
    "\n",
    "    #SARIMAX modeling with the choosen parameters  \n",
    "    model= SARIMAX(train_y,exog=train_X,order=step_wise.order)\n",
    "    results = model.fit()\n",
    "    #Predictions\n",
    "    predictions = results.predict(start=data_size - test_size, end=data_size - 1, exog=np.array(test_X))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73c35e-1f31-40c8-bd9e-f23823a081ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = modeling(data_processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
